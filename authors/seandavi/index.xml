<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>seandavi(s12)</title>
    <link>https://seandavi.github.io/authors/seandavi/</link>
      <atom:link href="https://seandavi.github.io/authors/seandavi/index.xml" rel="self" type="application/rss+xml" />
    <description>seandavi(s12)</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© 2016-2020</copyright>
    <image>
      <url>https://seandavi.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>seandavi(s12)</title>
      <link>https://seandavi.github.io/authors/seandavi/</link>
    </image>
    
    <item>
      <title>GenomicSuperSignature: Interpretation of RNA-Seq Experiments through Robust, Efficient Comparison to Public Databases</title>
      <link>https://seandavi.github.io/talk/2021-11-14-genomicsupersignature-at-supercomputer-cafcw/</link>
      <pubDate>Sun, 14 Nov 2021 16:30:00 -0400</pubDate>
      <guid>https://seandavi.github.io/talk/2021-11-14-genomicsupersignature-at-supercomputer-cafcw/</guid>
      <description>&lt;div class=&#34;responsive-wrap&#34;&gt;
  &lt;iframe src=&#34;https://docs.google.com/presentation/d/e/2PACX-1vT-qEQ7dJgx15fcwWNoHsxDe0MAbBzrR4ggM5UBxgymHL3duh_vFrpc9Ishg5AiMPpkBar5AHJw_xY_/embed?start=false&amp;amp;loop=false&amp;amp;delayms=3000&#34; frameborder=&#34;0&#34; width=&#34;960&#34; height=&#34;569&#34; allowfullscreen=&#34;true&#34; mozallowfullscreen=&#34;true&#34; webkitallowfullscreen=&#34;true&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>OmicIDX</title>
      <link>https://seandavi.github.io/project/omicidx/</link>
      <pubDate>Wed, 11 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://seandavi.github.io/project/omicidx/</guid>
      <description>&lt;p&gt;OmicIDX is an ecosystem that &lt;em&gt;treats metadata&lt;/em&gt; from public genomics
repositories as &lt;em&gt;data&lt;/em&gt;. Metadata collection from source repositories
updates occur regularly and processing using a purpose-build &lt;a href=&#34;https://github.com/omicidx/omicidx-parsers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;parsing
library&lt;/a&gt; produces standard
json format representations. The &lt;a href=&#34;https://github.com/omicidx/omicidx-builder&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OmicIDX
builder&lt;/a&gt; automates
&lt;a href=&#34;https://cloud.google.com/bigquery&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bigquery&lt;/a&gt; and web-based API
generation and updates. The &lt;a href=&#34;https://api.omicidx.cancerdatasci.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenAPI-based web
API&lt;/a&gt; enables performant
language-agnostic search, retrieval, and analysis of OmicIDX
data. Finally, data are augmented with &lt;a href=&#34;https://ii.nlm.nih.gov/MTI/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;natural language
processing&lt;/a&gt;
to produce Medical Subject Heading
&lt;a href=&#34;https://www.nlm.nih.gov/mesh/meshhome.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MeSH&lt;/a&gt;  mapping and with
heuristic text matching to map terms to ontologies.&lt;/p&gt;
&lt;p&gt;Datasets currently included in OmicIDX include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SRA
&lt;ul&gt;
&lt;li&gt;studies&lt;/li&gt;
&lt;li&gt;samples&lt;/li&gt;
&lt;li&gt;experiments&lt;/li&gt;
&lt;li&gt;runs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;dbGaP mapping from SRA&lt;/li&gt;
&lt;li&gt;Biosample
&lt;ul&gt;
&lt;li&gt;samples&lt;/li&gt;
&lt;li&gt;projects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;GEO
&lt;ul&gt;
&lt;li&gt;platforms&lt;/li&gt;
&lt;li&gt;series&lt;/li&gt;
&lt;li&gt;samples&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Data are augmented with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MeSH&lt;/li&gt;
&lt;li&gt;~200 Ontologies&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Build and deploy an NCBI GEO metadata fetch API</title>
      <link>https://seandavi.github.io/post/cloud-run-notes/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://seandavi.github.io/post/cloud-run-notes/</guid>
      <description>&lt;p&gt;In this post, I want to demonstrate building a simple web API converts
an NCBI &lt;a href=&#34;https://ncbi.nlm.nih.gov/geo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GEO&lt;/a&gt; accession and associated metadata to &lt;a href=&#34;https://www.digitalocean.com/community/tutorials/an-introduction-to-json&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;json&lt;/a&gt; format, and
then deploy that application as a web service on Google Cloud Platform
&lt;a href=&#34;https://cloud.google.com/run&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cloud Run&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I hear from GEOquery users that sometimes they just want to get the
metadata for one or more accessions rather than getting the entire GEO
record. My &lt;a href=&#34;https://github.com/omicidx/omicidx-parsers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;omicidx-parser&lt;/a&gt; library has functionality to do this
conversion. We will leverage this functionality to build a small web
application that we can deploy using &lt;a href=&#34;https://en.wikipedia.org/wiki/Serverless_computing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;serverless&lt;/a&gt; approach to stand up
an API that returns a &lt;a href=&#34;https://www.digitalocean.com/community/tutorials/an-introduction-to-json&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;json&lt;/a&gt; conversion of GEO metadata.&lt;/p&gt;
&lt;h2 id=&#34;tooling&#34;&gt;Tooling&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Google cloud platform, specifically &lt;a href=&#34;https://en.wikipedia.org/wiki/Serverless_computing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;serverless&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/run&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cloud Run&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;python programming language&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://fastapi.tiangolo.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fastapi&lt;/a&gt; library for web API development&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[docker] containers&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;git and github&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Code: &lt;a href=&#34;https://github.com/seandavi/blog-code/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/seandavi/blog-code/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-will-i-learn-and-do&#34;&gt;What will I learn and do?&lt;/h2&gt;
&lt;p&gt;In this post, we will learn the basics of &lt;a href=&#34;https://cloud.google.com/run&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cloud Run&lt;/a&gt; through
examples. Additionally, we will learn a bit about web app development
using the &lt;a href=&#34;https://fastapi.tiangolo.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fastapi&lt;/a&gt; python web framework.&lt;/p&gt;
&lt;p&gt;At the end of this post, you will have a containerized web application
running locally that can take a GEO accession and return a &lt;a href=&#34;https://www.digitalocean.com/community/tutorials/an-introduction-to-json&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;json&lt;/a&gt;
version of the metadata.&lt;/p&gt;
&lt;p&gt;If you have a Google Cloud Platform account that allows you to create
projects, you should be able to run your application in Google Cloud
Run.&lt;/p&gt;
&lt;h2 id=&#34;what-is-cloud-run&#34;&gt;What is Cloud Run?&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/run&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cloud Run&lt;/a&gt; is a fully managed compute platform that automatically
scales your stateless containers. In other words, write a web
application, place it in a &lt;a href=&#34;https://docker.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;docker container&lt;/a&gt;, and then deploy to the
cloud. Cloud Run is one of a family of technologies referred to as
&lt;a href=&#34;https://en.wikipedia.org/wiki/Serverless_computing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;serverless&lt;/a&gt; it abstracts away all infrastructure management. Cloud
Run is built upon an open standard, &lt;a href=&#34;https://knative.dev/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Knative&lt;/a&gt;, enabling the
portability of your applications.&lt;/p&gt;
&lt;h2 id=&#34;build-your-app&#34;&gt;Build your app&lt;/h2&gt;
&lt;p&gt;Sorry, but I&amp;rsquo;m going to let the code do most of the talking here. In
short, Google Cloud Run supports any web development language or
framework that can be deployed as a docker container.&lt;/p&gt;
&lt;p&gt;Here, I will use python and adopt &lt;a href=&#34;https://fastapi.tiangolo.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fastapi&lt;/a&gt; a framework for building
performant REST APIs.&lt;/p&gt;
&lt;p&gt;The GEO parsing will leverage the &lt;a href=&#34;https://github.com/omicidx/omicidx-parsers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;omicidx-parser&lt;/a&gt; library.&lt;/p&gt;
&lt;h2 id=&#34;containers-are-front-and-center&#34;&gt;Containers are front-and-center&lt;/h2&gt;
&lt;p&gt;Google&amp;rsquo;s &lt;a href=&#34;https://cloud.google.com/run&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cloud Run&lt;/a&gt; creates a &amp;ldquo;service&amp;rdquo; that accepts http requests
and returns responses. The requests and responses are not predefined
by Cloud Run, allowing any approach that your chosen programming
language supports. Once your web application is written and tested
locally, create a &lt;a href=&#34;https://docs.docker.com/develop/develop-images/dockerfile_best-practices/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dockerfile&lt;/a&gt; that generates a containerized version
of it. The generated docker container is what you will pass along to
&lt;a href=&#34;https://cloud.google.com/run&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cloud Run&lt;/a&gt; as the application. &lt;a href=&#34;https://cloud.google.com/run&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cloud Run&lt;/a&gt; will then create a
&amp;ldquo;service&amp;rdquo; by setting up your docker container to run &amp;ldquo;on demand&amp;rdquo; when
a web request is directed to it.&lt;/p&gt;
&lt;p&gt;Any programming dependencies, operating system or system dependencies,
or necessary software are simply included in the &lt;a href=&#34;https://docs.docker.com/develop/develop-images/dockerfile_best-practices/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dockerfile&lt;/a&gt;
description to be incorporated into the container. Local testing is
straightforward by simply running the docker container locally.&lt;/p&gt;
&lt;h2 id=&#34;example-application-and-deployment&#34;&gt;Example application and deployment&lt;/h2&gt;
&lt;p&gt;As of today, I am using &lt;a href=&#34;https://python-poetry.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;poetry&lt;/a&gt; for python dependency management
(think pip and virtualenv replacement) and package building. To get
started with poetry, install:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  | python
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I&amp;rsquo;ll leave the poetry parts of things out for now, but you will see
some poetry command lines to build the cloud run environment.&lt;/p&gt;
&lt;p&gt;Next, checkout the &lt;a href=&#34;https://github.com/seandavi/blog-code&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;example repo&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/seandavi/blog-code
cd blog-code/geo-metadata-cloud-run/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To set up a local development environment and then test the app
locally, I use a couple of poetry commands (see poetry docs for what
these do, specifically).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;poetry install
poetry run uvicorn app.main:app
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then, navigate to http://localhost:8000/docs. There, by default, you are redirected to the auto-generated &lt;a href=&#34;https://swagger.io/docs/specification/about/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenAPI&lt;/a&gt; API documentation (yes, you get this &lt;em&gt;for free&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;To see the results for a specific accession, click here: http://localhost:8000/geo/GSM48743. An example response will look like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;{
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;GSM48743&amp;#34;&lt;/span&gt;: {
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;title&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Patient sample ST163, Liposarcoma&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;status&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Public on Oct 11 2005&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;submission_date&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2005-04-21&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;last_update_date&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2005-11-22&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;RNA&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;anchor&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;contact&amp;#34;&lt;/span&gt;: {
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;city&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Bethesda&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;: {
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;first&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Sean&amp;#34;&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;middle&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;last&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Davis&amp;#34;&lt;/span&gt;
            },
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;email&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sdavis2@mail.nih.gov&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;state&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MD&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;address&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;37 Convent Drive, Room 6138&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;department&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;country&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;USA&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;web_link&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;institute&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;National Cancer Institute&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;zip_postal_code&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
            &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;phone&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;301-435-2652&amp;#34;&lt;/span&gt;
        },
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;description&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Diagnosis: Liposarcoma\nKeywords = sarcoma, cDNA, Liposarcoma&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;accession&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;GSM48743&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;biosample&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;tag_count&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;tag_length&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;platform_id&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;GPL1977&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;hyb_protocol&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;channel_count&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;scan_protocol&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;data_row_count&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;12600&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;library_source&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;overall_design&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;sra_experiment&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;data_processing&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;supplemental_files&amp;#34;&lt;/span&gt;: [
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;NONE&amp;#34;&lt;/span&gt;
        ],
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;channels&amp;#34;&lt;/span&gt;: [
            {
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;label&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;taxid&amp;#34;&lt;/span&gt;: [
                    &lt;span style=&#34;color:#ae81ff&#34;&gt;9606&lt;/span&gt;
                ],
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;molecule&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;total RNA&amp;#34;&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;organism&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Homo sapiens&amp;#34;&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;source_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Liposarcoma&amp;#34;&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;label_protocol&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;growth_protocol&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;extract_protocol&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;treatment_protocol&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;characteristics&amp;#34;&lt;/span&gt;: [
                    
                ]
            },
            {
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;label&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;taxid&amp;#34;&lt;/span&gt;: [
                    &lt;span style=&#34;color:#ae81ff&#34;&gt;9606&lt;/span&gt;
                ],
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;molecule&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;total RNA&amp;#34;&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;organism&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Homo sapiens&amp;#34;&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;source_name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Pooled sarcoma cell lines&amp;#34;&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;label_protocol&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;growth_protocol&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;extract_protocol&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;treatment_protocol&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;,
                &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;characteristics&amp;#34;&lt;/span&gt;: [
                    
                ]
            }
        ],
        &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;contributor&amp;#34;&lt;/span&gt;: [
            
        ]
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;At this point, the web application is running locally. We can
&amp;ldquo;containerize&amp;rdquo; the application by building the docker container. The
&lt;a href=&#34;https://github.com/seandavi/blog-code/blob/master/geo-metadata-cloud-run/Dockerfile&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;associated Dockerfile&lt;/a&gt; has instructions for doing so. To actually
build the docker image, do the following, replacing &lt;code&gt;PROJECT_ID&lt;/code&gt; below with
your GCP project ID. You can view your project ID by running the
command.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;gcloud config get-value project.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;export PROJECT_ID&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;my-google-project-name&amp;#39;&lt;/span&gt;
docker build -t gcr.io/&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;PROJECT_ID&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;/geo-cloud-run .
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Push the docker image to the Google Cloud Project image
repository. You can also use dockerhub name/url if you like.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker push gcr.io/&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;PROJECT_ID&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;/geo-cloud-run
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run the app as a dockerized app locally.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker run -p 8000:80 gcr.io/&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;PROJECT_ID&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;/geo-cloud-run 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Again, you should now be able to access the API at http://localhost:8000/docs.&lt;/p&gt;
&lt;p&gt;One more step, deployment, gets us the application running in the
cloud as a serverless application. Deploy using the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;gcloud run deploy --image gcr.io/&lt;span style=&#34;color:#e6db74&#34;&gt;${&lt;/span&gt;PROJECT_ID&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;/geo-cloud-run --platform managed
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;You will be prompted for the service name: press Enter to accept the
default name, geo-cloud-run&lt;/li&gt;
&lt;li&gt;You will be prompted for region: select the region of your choice,
for example us-central1.&lt;/li&gt;
&lt;li&gt;You will be prompted to allow unauthenticated invocations: respond &lt;code&gt;y&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then wait a few moments until the deployment is complete. On success,
the command line displays the service URL. If you navigate to that
service URL, you will be accessing your &lt;em&gt;entirely serverless&lt;/em&gt;
application. Build more complicated applications by simply:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Adjust python code.&lt;/li&gt;
&lt;li&gt;Rebuild docker image.&lt;/li&gt;
&lt;li&gt;run &lt;code&gt;gcloud run update ....&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;When completed, simply run &lt;code&gt;gcloud run delete ....&lt;/code&gt; to remove your
service and application.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building R Binary Packages for Linux</title>
      <link>https://seandavi.github.io/post/build-linux-r-binary-packages/</link>
      <pubDate>Mon, 14 Oct 2019 12:22:47 -0400</pubDate>
      <guid>https://seandavi.github.io/post/build-linux-r-binary-packages/</guid>
      <description>&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;One of the challenges of producing a performant build environment for linux, such as what might
be used to have developers test software in &lt;em&gt;identical&lt;/em&gt; environments, is the need to compile
R packages from source on linux. If, however, one had an identical set of installed libraries, kernel
version, compiler, etc., we could use binary packages in linux as well.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docker.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Docker&lt;/a&gt; provides just such a shareable and identical environment for linux. Recent work by
Levi Waldron and Nitesh Turaga to produce the &lt;a href=&#34;https://hub.docker.com/r/bioconductor/bioconductor_full&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bioconductor_full&lt;/a&gt; docker image will allow for
nearly &lt;strong&gt;all&lt;/strong&gt; bioconductor packages to be installed, as the underlying system dependencies
are all included.&lt;/p&gt;
&lt;h2 id=&#34;docs-from-r-on-building-binaries&#34;&gt;Docs from R on building binaries&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://www.hep.by/gnu/r-patched/r-exts/R-exts_20.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;docs on building binary R packages&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The recommended method of building binary packages is to use
&lt;code&gt;R CMD INSTALL --build pkg&lt;/code&gt; where &lt;code&gt;pkg&lt;/code&gt; is either the name of a source tarball (in the usual &lt;code&gt;.tar.gz&lt;/code&gt; format) or the location of the directory of the package source to be built.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;R CMD INSTALL --build&lt;/code&gt; operates by first installing the package and then packing the installed binaries into the appropriate binary package file for the particular platform.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;By default, &lt;code&gt;R CMD INSTALL --build&lt;/code&gt; will attempt to install the package into the default library tree for the local installation of R. This has two implications:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;If the installation is successful, it will overwrite any existing installation of the same package. The default library tree must have write permission; if not, the package will not install and the binary will not be created. To prevent changes to the present working installation or to provide an install location with write access, create a suitably located directory with write access and use the -l option to build the package in the chosen location. The usage is then&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;R CMD INSTALL -l location --build pkg
&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;
&lt;p&gt;where &lt;code&gt;location&lt;/code&gt; is the chosen directory with write access. The package will be installed as a subdirectory of &lt;code&gt;location&lt;/code&gt;, and the package binary will be created in the current directory.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;walkthrough&#34;&gt;Walkthrough&lt;/h2&gt;
&lt;p&gt;With that background in place, by starting a docker container from bioconductor_full, we can
build binary packages that can be shared with others who are also running using bioconductor_full.&lt;/p&gt;
&lt;p&gt;The next command assumes that docker is running.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run -v PATH_TO_LOCAL_STORAGE_DIRECTORY:/data \
  --name bioc_full \
  -e PASSWORD=&amp;lt;YOUR_PASSWORD_OF_CHOICE&amp;gt; \
  -p 8787:8787 \
  bioconductor/bioconductor_full:devel 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;code&gt;PATH_TO_LOCAL_STORAGE_DIRECTORY&lt;/code&gt; should be replaced with the local directlry
where the binary packages will land as they are built inside the container. Packages can
then be reused or copied somewhere else for installation as binaries.&lt;/p&gt;
&lt;p&gt;After running the &lt;code&gt;docker run&lt;/code&gt; command above, you should be able to navigate to
https://localhost:8787/ (or whatever your docker host address is). You will be presented
with an Rstudio login. Login with username=&lt;code&gt;rstudio&lt;/code&gt; and
password=&lt;code&gt;YOUR_PASSWORD_OF_CHOICE&lt;/code&gt; as set above.&lt;/p&gt;
&lt;h2 id=&#34;install-and-build-binaries&#34;&gt;Install and build binaries&lt;/h2&gt;
&lt;p&gt;Binary packages, after being installed and built, will be placed in the current working
directory. I switch to the directory that is mapped back to the host so that I can
keep the binary packages around after the container stops.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r}&#34; data-lang=&#34;{r}&#34;&gt;setwd(&#39;/data&#39;) # to drop binary tarballs into this directory
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After logging into Rstudio, execute the following command. Note the &lt;code&gt;INSTALL_opts&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r}&#34; data-lang=&#34;{r}&#34;&gt;# Biocmanager will be installed already for bioconductor_full
BiocManager::install(&#39;limma&#39;, INSTALL_opts=&#39;--build&#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;These installation options will copy the installed binary package(s) to &lt;code&gt;/data&lt;/code&gt;. These will end
up on the docker host machine in the &lt;code&gt;PATH_TO_LOCAL_STORAGE_DIRECTORY&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r}&#34; data-lang=&#34;{r}&#34;&gt;Bioconductor version 3.10 (BiocManager 1.30.4), R 3.6.1 (2019-07-05)
Installing package(s) &#39;limma&#39;
trying URL &#39;https://bioconductor.org/packages/3.10/bioc/src/contrib/limma_3.41.18.tar.gz&#39;
Content type &#39;application/x-gzip&#39; length 1493044 bytes (1.4 MB)
==================================================
downloaded 1.4 MB

* installing *source* package âlimmaâ ...
** using staged installation
** libs
gcc -I&amp;quot;/usr/local/lib/R/include&amp;quot; -DNDEBUG   -I/usr/local/include  -fpic  -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g  -c init.c -o init.o
gcc -I&amp;quot;/usr/local/lib/R/include&amp;quot; -DNDEBUG   -I/usr/local/include  -fpic  -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g  -c normexp.c -o normexp.o
gcc -I&amp;quot;/usr/local/lib/R/include&amp;quot; -DNDEBUG   -I/usr/local/include  -fpic  -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g  -c weighted_lowess.c -o weighted_lowess.o
gcc -shared -L/usr/local/lib/R/lib -L/usr/local/lib -o limma.so init.o normexp.o weighted_lowess.o -L/usr/local/lib/R/lib -lR
installing to /usr/local/lib/R/site-library/00LOCK-limma/00new/limma/libs
** R
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded from temporary location
** checking absolute paths in shared objects and dynamic libraries
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation path
* creating tarball
packaged installation of âlimmaâ as âlimma_3.41.18_R_x86_64-pc-linux-gnu.tar.gzâ
* DONE (limma)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Check what we created:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r}&#34; data-lang=&#34;{r}&#34;&gt;dir(&#39;/data&#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Your version of limma may differ.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r}&#34; data-lang=&#34;{r}&#34;&gt;[1] &amp;quot;limma_3.41.18_R_x86_64-pc-linux-gnu.tar.gz&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;These binary packages can be installed just like any &lt;code&gt;.tar.gz&lt;/code&gt; package but will
be intalled very quickly like on Mac OS and Windows.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remember to kill the docker container after you are done&lt;/strong&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Experimenting with Github Actions</title>
      <link>https://seandavi.github.io/post/learning-github-actions/</link>
      <pubDate>Fri, 11 Oct 2019 11:08:16 -0400</pubDate>
      <guid>https://seandavi.github.io/post/learning-github-actions/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/features/package-registry&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub Actions&lt;/a&gt; allow flexible and potentially complicated actions
that comprise workflows that respond to &lt;a href=&#34;https://developer.github.com/webhooks/#events&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;repository events&lt;/a&gt; on Github. Continuous
integration, messaging Slack, greeting new contributors, deploying
applications, and many other templates are ready for customization and
integration into any repo.&lt;/p&gt;
&lt;p&gt;As of this writing, GitHub Actions are available as a &lt;em&gt;beta&lt;/em&gt; feature,
requiring &lt;a href=&#34;https://github.com/features/actions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;signup&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;definitionshttpshelpgithubcomenarticlesabout-github-actionscore-concepts-for-github-actions&#34;&gt;&lt;a href=&#34;https://help.github.com/en/articles/about-github-actions#core-concepts-for-github-actions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Definitions&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id=&#34;action&#34;&gt;Action&lt;/h3&gt;
&lt;p&gt;An action is the smallest portable building block of a
workflow. Actions are combined as steps to form a workflow. Actions can be
created from scratch, modified from &lt;a href=&#34;https://github.com/actions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;publicly available actions&lt;/a&gt;, and
shared with others.&lt;/p&gt;
&lt;h3 id=&#34;workflow&#34;&gt;Workflow&lt;/h3&gt;
&lt;p&gt;A workflow is a collection of steps (actions) that describe a process
that will execute in response to GitHub &lt;a href=&#34;https://developer.github.com/webhooks/#events&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;repository events&lt;/a&gt;. A YAML
file that defines your workflow configuration with at least one
job. This file lives in the root of your GitHub repository in the
&lt;code&gt;.github/workflows&lt;/code&gt; directory. Multiple workflow files may exist and
all will be active.&lt;/p&gt;
&lt;h3 id=&#34;step&#34;&gt;Step&lt;/h3&gt;
&lt;p&gt;A step is a set of tasks performed by a job. Each step in a job
executes in the same virtual environment, allowing the actions in that
job to share information using the filesystem. Steps can run commands
(shell commands, etc.) or actions.&lt;/p&gt;
&lt;h3 id=&#34;virtual-environment&#34;&gt;Virtual environment&lt;/h3&gt;
&lt;p&gt;GitHub has hosts for Linux, macOS, and Windows that can serve as
execution environments for workflows.&lt;/p&gt;
&lt;h3 id=&#34;runner&#34;&gt;Runner&lt;/h3&gt;
&lt;p&gt;Jobs run on a service that waits in virtual environment that waits for available
jobs. The runner takes jobs one-at-a-time and runs each, reporting
logs, etc., back to Github.&lt;/p&gt;
&lt;h3 id=&#34;event&#34;&gt;Event&lt;/h3&gt;
&lt;p&gt;Workflows can be triggered by a [repository event] such as a push, a
new issue, etc.&lt;/p&gt;
&lt;h3 id=&#34;artifact&#34;&gt;Artifact&lt;/h3&gt;
&lt;p&gt;Artifacts are the files that are created during a workflow. These can
be deployed, used in other workflows, published, etc. Additional
actions allow working with artifacts.&lt;/p&gt;
&lt;h2 id=&#34;walkthrough&#34;&gt;Walkthrough&lt;/h2&gt;
&lt;h3 id=&#34;create-repo&#34;&gt;Create repo&lt;/h3&gt;
&lt;p&gt;Here, I simulate creating a simple python package by forking &lt;a href=&#34;https://github.com/bast/somepackage&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this
example repo&lt;/a&gt; by
&lt;a href=&#34;https://github.com/bast&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bast&lt;/a&gt;. The package is to exemplify some best
practices for structuring python code. However, here it serves as a
simple example of a formal python package that we can build and test.&lt;/p&gt;
&lt;p&gt;Login to Github, navigate to the &lt;a href=&#34;https://github.com/bast/somepackage&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;example repo&lt;/a&gt;, and &lt;a href=&#34;https://help.github.com/en/articles/fork-a-repo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fork the
repo&lt;/a&gt;.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-fork-the-example-repohttpsgithubcombastsomepackage&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://seandavi.github.io/post/learning-github-actions/fork-repo_hufba7682a0eb300813e1b68b0c8690756_502006_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Fork the &amp;lt;a href=&amp;#34;https://github.com/bast/somepackage&amp;#34;&amp;gt;example repo&amp;lt;/a&amp;gt;.&#34;&gt;


  &lt;img data-src=&#34;https://seandavi.github.io/post/learning-github-actions/fork-repo_hufba7682a0eb300813e1b68b0c8690756_502006_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;3370&#34; height=&#34;1664&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Fork the &lt;a href=&#34;https://github.com/bast/somepackage&#34;&gt;example repo&lt;/a&gt;.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;After forking, a fresh package will be available in your repository.&lt;/p&gt;
&lt;h3 id=&#34;add-a-github-action&#34;&gt;Add a github action&lt;/h3&gt;
&lt;p&gt;After ensuring that you have [signed up] for Github Actions and have
verified that you are &amp;ldquo;in&amp;rdquo; by noticing the &lt;code&gt;Actions&lt;/code&gt; button at the top
of your github repository:&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-the-github-actions-button-should-be-present-in-order-to-proceed&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://seandavi.github.io/post/learning-github-actions/action-button_hufca21c42c756e02db03ecac215a46111_94380_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;The Github Actions button should be present in order to proceed.&#34;&gt;


  &lt;img data-src=&#34;https://seandavi.github.io/post/learning-github-actions/action-button_hufca21c42c756e02db03ecac215a46111_94380_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1792&#34; height=&#34;458&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    The Github Actions button should be present in order to proceed.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Now, we can proceed with adding a workflow from the set of recommended
workflow templates (or others). Clicking on the &lt;code&gt;Actions&lt;/code&gt; button will
bring up the following screen.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-choose-the-python-package-workflow&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://seandavi.github.io/post/learning-github-actions/choose-action_hu18fe83e46e92b88e675b257dc24db559_469675_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Choose the python package workflow.&#34;&gt;


  &lt;img data-src=&#34;https://seandavi.github.io/post/learning-github-actions/choose-action_hu18fe83e46e92b88e675b257dc24db559_469675_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;3288&#34; height=&#34;1522&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Choose the python package workflow.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Click on the &lt;code&gt;Set up this workflow&lt;/code&gt; on the &amp;ldquo;Python package&amp;rdquo;
card. That will bring up the following screen.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-the-workflow-editor&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://seandavi.github.io/post/learning-github-actions/workflow-editor_hu22857dbc6f1f1e0dcd8dd1accc15cab9_271164_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;The workflow editor.&#34;&gt;


  &lt;img data-src=&#34;https://seandavi.github.io/post/learning-github-actions/workflow-editor_hu22857dbc6f1f1e0dcd8dd1accc15cab9_271164_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;2240&#34; height=&#34;1312&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    The workflow editor.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;What is happening at this point is that Github is about to add a new
file to your repository. The file will be located at
&lt;code&gt;somepackage/.github/workflows&lt;/code&gt;. Edit the filename as you see
fit.&lt;/p&gt;
&lt;p&gt;The contents of the workflow file will look like the listing below by
default and follows &lt;a href=&#34;https://help.github.com/en/articles/workflow-syntax-for-github-actions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the workflow
syntax&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;name: Python package

on: [push]

jobs:
  build:

    runs&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;on: ubuntu&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;latest
    strategy:
      max&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;parallel: &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;
      matrix:
        python&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;version: [&lt;span style=&#34;color:#ae81ff&#34;&gt;2.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3.5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3.6&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3.7&lt;/span&gt;]

    steps:
    &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; uses: actions&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;checkout&lt;span style=&#34;color:#a6e22e&#34;&gt;@v1&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; name: Set up Python &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;{{ matrix&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;python&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;version }}
      uses: actions&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;setup&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;python&lt;span style=&#34;color:#a6e22e&#34;&gt;@v1&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt;:
        python&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;version: &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;{{ matrix&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;python&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;version }}
    &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; name: Install dependencies
      run: &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;
        python &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;m pip install &lt;span style=&#34;color:#f92672&#34;&gt;--&lt;/span&gt;upgrade pip
        pip install &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;r requirements&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;txt
    &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; name: Lint &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; flake8
      run: &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;
        pip install flake8
        &lt;span style=&#34;color:#75715e&#34;&gt;# stop the build if there are Python syntax errors or undefined names&lt;/span&gt;
        flake8 &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;--&lt;/span&gt;count &lt;span style=&#34;color:#f92672&#34;&gt;--&lt;/span&gt;select&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;E9,F63,F7,F82 &lt;span style=&#34;color:#f92672&#34;&gt;--&lt;/span&gt;show&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;source &lt;span style=&#34;color:#f92672&#34;&gt;--&lt;/span&gt;statistics
        &lt;span style=&#34;color:#75715e&#34;&gt;# exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide&lt;/span&gt;
        flake8 &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;--&lt;/span&gt;count &lt;span style=&#34;color:#f92672&#34;&gt;--&lt;/span&gt;exit&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;zero &lt;span style=&#34;color:#f92672&#34;&gt;--&lt;/span&gt;max&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;complexity&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;--&lt;/span&gt;max&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;line&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;length&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;127&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;--&lt;/span&gt;statistics
    &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; name: Test &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; pytest
      run: &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;
        pip install pytest
        pytest
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;commit-new-workflow-file&#34;&gt;Commit new workflow file&lt;/h3&gt;
&lt;p&gt;Once you have made any edits (no need to, though), go ahead and click
the &lt;code&gt;Start Commit&lt;/code&gt; button.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-make-the-first-commit&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://seandavi.github.io/post/learning-github-actions/first-commit_hu2a458d7651905bf4de47ef29fe24ce96_153655_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Make the first commit.&#34;&gt;


  &lt;img data-src=&#34;https://seandavi.github.io/post/learning-github-actions/first-commit_hu2a458d7651905bf4de47ef29fe24ce96_153655_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1074&#34; height=&#34;1282&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Make the first commit.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;build-results&#34;&gt;Build results&lt;/h3&gt;
&lt;p&gt;By navigating back to &lt;code&gt;Actions&lt;/code&gt;, you should see that the workflow is
running or has already completed. An example of what a running
workflow might look like is below.&lt;/p&gt;


















&lt;figure id=&#34;figure-image-credit-github-bloghttpsgithubblog2019-08-08-github-actions-now-supports-ci-cd&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://github.blog/wp-content/uploads/2019/08/streaming.gif?w=918&amp;amp;resize=918%2C802&#34; data-caption=&#34;Image Credit: &amp;lt;a href=&amp;#34;https://github.blog/2019-08-08-github-actions-now-supports-ci-cd/&amp;#34;&amp;gt;GitHub Blog&amp;lt;/a&amp;gt;&#34;&gt;


  &lt;img src=&#34;https://github.blog/wp-content/uploads/2019/08/streaming.gif?w=918&amp;amp;resize=918%2C802&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Image Credit: &lt;a href=&#34;https://github.blog/2019-08-08-github-actions-now-supports-ci-cd/&#34;&gt;GitHub Blog&lt;/a&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;You are free to investigate the logs, etc.&lt;/p&gt;
&lt;h3 id=&#34;modifying-the-workflow&#34;&gt;Modifying the workflow&lt;/h3&gt;
&lt;p&gt;Modifying the workflow is as simple as making edits to the
&lt;code&gt;.github/workflows/...yaml&lt;/code&gt; file. For example, you might consider
changing the name of the workflow and modifying the python versions
that are used for testing.&lt;/p&gt;
&lt;h3 id=&#34;workflow-status-badge&#34;&gt;Workflow status badge&lt;/h3&gt;
&lt;p&gt;Follow &lt;a href=&#34;https://help.github.com/en/articles/configuring-a-workflow#adding-a-workflow-status-badge-to-your-repository&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;these
instructions&lt;/a&gt;
to add a status badge to your repo that will be updated with each
workflow execution. Example code is here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[![Actions
Status](https://github.com/seandavi/somepackage/workflows/Python%20package/badge.svg)](https://github.com/seandavi/somepackage/actions)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note the &lt;code&gt;%20&lt;/code&gt; that represents a url-encoded &lt;code&gt;space&lt;/code&gt; character. The resulting badge looks like this:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/seandavi/somepackage/actions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://github.com/seandavi/somepackage/workflows/Python%20package/badge.svg&#34; alt=&#34;Actions Status&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Github actions and workflows add continuous integration and other
capabilities that are configurable via text files that are captured
and versioned alongside code. Therefore, actions can be shared,
modified, and manipulated with standard text editors, etc.&lt;/p&gt;
&lt;p&gt;Many actions are &lt;a href=&#34;https://github.com/actions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;publicly
available&lt;/a&gt;. Example workflows are also
&lt;a href=&#34;https://github.com/actions/starter-workflows&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;easy to find&lt;/a&gt;. For
those who are partial to &lt;em&gt;R&lt;/em&gt;, there is the R-centric
&lt;a href=&#34;https://r-lib.github.io/ghactions/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ghactions&lt;/a&gt; package that 1)
provides workflow templates for common R projects (packages,
RMarkdown, â¦) with sensible defaults and 2) wraps and curates relevant
existing external actions, such as those to deploy to GitHub Pages or
Netlify.&lt;/p&gt;
&lt;p&gt;Hardware available as of this writing is &lt;a href=&#34;https://help.github.com/en/articles/virtual-environments-for-github-actions#supported-virtual-environments-and-hardware-resources&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;described
here&lt;/a&gt;
and includes Windows, Linux, and MacOS environments. When a workflow
is running, multiple &lt;a href=&#34;https://help.github.com/en/articles/virtual-environments-for-github-actions#environment-variables&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;environment
variables&lt;/a&gt;
are set and accessible to software. Github actions allow the user to
create
&lt;a href=&#34;https://help.github.com/en/articles/virtual-environments-for-github-actions#creating-and-using-secrets-encrypted-variables&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;secrets&lt;/a&gt;
to securely store credentials for use inside run environments. Github
actions are container-ready, allowing &lt;a href=&#34;https://help.github.com/en/articles/creating-a-docker-container-action&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;containerized
actions&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This post, like many of my posts, is very operational, but I have
found that a worked example is usually more valuable than long
expository posts. That said, I always appreciate comments and
suggestions for improvements (see below).&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/features/package-registry&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub Package Registry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/features/package-registry&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub Actions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://help.github.com/en/articles/workflow-syntax-for-github-actions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Workflow Syntax&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://developer.github.com/webhooks/#events&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;repository events&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/actions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;publicly available actions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.community/t5/GitHub-Actions/bd-p/actions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Community support site&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Howard County Community College STEM Career Panel</title>
      <link>https://seandavi.github.io/talk/2019-10-08-hcc-stem-career-fair/</link>
      <pubDate>Tue, 08 Oct 2019 16:30:00 -0400</pubDate>
      <guid>https://seandavi.github.io/talk/2019-10-08-hcc-stem-career-fair/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Howard County Community College STEM Career Panel</title>
      <link>https://seandavi.github.io/talk/abc/</link>
      <pubDate>Tue, 08 Oct 2019 16:30:00 -0400</pubDate>
      <guid>https://seandavi.github.io/talk/abc/</guid>
      <description>&lt;div class=&#34;responsive-wrap&#34;&gt;
  &lt;iframe src=&#34;https://docs.google.com/presentation/d/e/2PACX-1vQU7CFxThgfBk_TM-ozA6gJVo2hCRBnChwVwt2qtdCZoYZbZbaTMEYVbn4BCAZD8lTzjUx1SDXT2MzX/embed?start=false&amp;amp;loop=false&amp;amp;delayms=3000&#34; frameborder=&#34;0&#34; width=&#34;960&#34; height=&#34;569&#34; allowfullscreen=&#34;true&#34; mozallowfullscreen=&#34;true&#34; webkitallowfullscreen=&#34;true&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Symposium: Participants Share Data 2019</title>
      <link>https://seandavi.github.io/project/nci-participants-share-data-2019/</link>
      <pubDate>Thu, 26 Sep 2019 17:44:07 -0400</pubDate>
      <guid>https://seandavi.github.io/project/nci-participants-share-data-2019/</guid>
      <description>&lt;p&gt;We convened a &lt;a href=&#34;https://events.cancer.gov/dccp/pcgdr/agenda&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;symposium on September 26-27,
2019&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The landscape of genomic medicine is rapidly evolving and includes
direct access to low-cost genomic sequencing through
direct-to-consumer genetic testing and commercial services providing
sequencing and interpretation. Increasingly, individuals want to share
their genomic data and associated clinical information for research
purposes. Several models exist to enable personal control of sharing
of genomics data. For individuals who want to make their personal
genomic data available for research or third parties for analysis or
interpretation, little support exists to answer questions, provide
technical support, or give feedback on the value of their data. Under
the auspices of the Cancer Moonshot (sm), NCI welcomes advocates,
policy leaders, and the public to participate in a two-day,
multisession workshop to explore the impact of personal control of
genomic data sharing to research, clinical care, and participants
well-being and engagement.&lt;/p&gt;
&lt;p&gt;The symposium hosted sessions on the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Motivations for and perceptions of participants controlling their
own data&lt;/li&gt;
&lt;li&gt;Facilitating personal control of sharing data: existing approaches
and platforms&lt;/li&gt;
&lt;li&gt;Risks and benefits to participants and their communities&lt;/li&gt;
&lt;li&gt;Sharing data in healthcare settings&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please sign up for our &lt;a href=&#34;https://list.nih.gov/cgi-bin/wa.exe?SUBED1=PARTICIPANTSHAREDDATASYMPOSIUM&amp;amp;A=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mailing list&lt;/a&gt; for updates about the symposium.&lt;/p&gt;
&lt;p&gt;For questions regarding this symposium, email &lt;a href=&#34;mailto:NCIParticipantShareData@mail.nih.gov&#34;&gt;NCIParticipantShareData@mail.nih.gov&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
